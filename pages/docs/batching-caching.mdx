import { Info, Warning } from "@/components/Callout"

# Batching & Caching

Before we dig into the Effect's solution to batching and caching let's start with a description of the problem.

It is very common in apps to depend on a number of external data sources like:

- HTTP APIs
- Databases
- Filesystems

## Model Definition

Let's start with a fairly minimal model description:

```ts filename="Model.ts" file=<rootDir>/src/guide/batching-caching/Model.ts
import { Effect } from "effect"

interface User {
  readonly _tag: "User"
  readonly id: number
  readonly name: string
  readonly email: string
}

class GetUserError {
  readonly _tag = "GetUserError"
}

interface Todo {
  readonly _tag: "Todo"
  readonly id: number
  readonly message: string
  readonly ownerId: number
}

class GetTodosError {
  readonly _tag = "GetTodosError"
}

class SendEmailError {
  readonly _tag = "SendEmailError"
}
```

<Info>
  In a real world scenario we may want to use a more precise types instead of
  directly using primitives for identifiers (see the `Brand` module). We may
  also want to include more information in the errors.
</Info>

## Classic Approach

Given such a model we usually write up functions to call some API (or database, etc.) like the following:

```ts filename="API.ts" file=<rootDir>/src/guide/batching-caching/API.ts

```

<Info>
  In a real world scenario we may not want to trust our APIs to actually return
  the expected data - for doing this properly you can use `@effect/schema` or
  similar alternatives such as `zod`.
</Info>

When using the utilities we defined it is normal to end up with code that looks like the following:

```ts filename="index.ts" file=<rootDir>/src/guide/batching-caching/index.ts

```

Here we used the `forEach` to repeat an `Effect` for every `Todo` and the `Effect` repeated
first fetches the `User` who owns the todo and then sends an email.

We like writing code this way because it is **very expressive** and very easy to read, but is it **efficient**?

This code will execute tons of individual API calls. Many todos will likely have the same owner and
our APIs may also provide batched alternatives where you can request as many users as you would like to in one call.

So what can we do? Rewrite all our code to use a different form of API? Should we really do that?

Well **not anymore.**

## Declaring Requests

Let's rewrite our example to be as efficient as possible - we'll start by writing a model for the requests that our data sources support:

```ts filename="RequestModel.ts" file=<rootDir>/src/guide/batching-caching/RequestModel.ts

```

## Declaring Resolvers

Now that we have our requests defined it is time to tell Effect how to resolve those requests. That's where we would use a `RequestResolver`.

Here we will define a single resolver per query. There is no right or wrong answer in how granular your resolvers should be
but usually you will split up your resolvers based on which API calls can be batched.

```ts filename="Resolvers.ts" file=<rootDir>/src/guide/batching-caching/Resolvers.ts

```

<Info>
  Resolvers can also access context like any other `Effect` and there are many
  different ways of creating resolvers. You may want to check the reference
  documentation of the `RequestResolver` module next.
</Info>

## Defining Queries

At this point we are ready to plug the pieces together! Let's do just that:

```ts filename="Queries.ts" file=<rootDir>/src/guide/batching-caching/Queries.ts

```

It looks like we are back at the beginning, same exact types and same exact composition.

But now the following program:

```ts filename="index.ts" file=<rootDir>/src/guide/batching-caching/index-queries.ts

```

Will only require **3** queries to be executed to our APIs instead of **1 + 2n** where **n** is the number of todos.

## Resolvers with Context

There may be cases where you want to access some context as part of the request resolver, in order for requests to be
batchable the resolver they reference has to be the same so it is important to avoid over providing context to a
resolver because having even two slightly different services makes the resolvers incompatible leading to no batching.

To avoid easy mistakes we decided to force the context of the resolver passed to `Effect.request` to `never` so that
you always have to specify how context is accessed.

Let's see how we would do it:

```ts filename="ResolversWithContext.ts" file=<rootDir>/src/guide/batching-caching/ResolversWithContext.ts

```

We can see now that the type of `GetTodosResolver` is no longer a `RequestResolver` but instead it is:

```ts
Effect.Effect<HttpService, never, RequestResolver<GetTodos, never>>
```

which is an `Effect` that access the `HttpService` and returns a composed resolver that has the minimal context ready to use.

Once we have such `Effect` we can directly use it in our request definition:

```ts filename="QueriesWithContext.ts" file=<rootDir>/src/guide/batching-caching/QueriesWithContext.ts

```

We can see that the `Effect` correctly requires `HttpService` to be provided.

Alternatively you can create `RequestResolver`s as part of layers direcly accessing or closing over context from construction.

For example:

```ts filename="QueriesFromLayers.ts" file=<rootDir>/src/guide/batching-caching/QueriesFromLayers.ts

```

This way is probably the best for most of the cases given that layers are the natural primitive where to wire services together.

## Controlling Batching

Batching can be locally disabled using the `Effect.withRequestBatching("off"){:ts}` utility in the following way:

```ts {9} filename="index.ts" file=<rootDir>/src/guide/batching-caching/withRequestBatching.ts

```

## Request Caching

Up to this point we optimized how requests are executed but there is still a catch - we are not doing any caching.

This leads to request duplication...

Fortunately we also have a primitive for caching in `Effect` and we use that to automatically cache requests.

```ts {9} filename="Queries.ts" file=<rootDir>/src/guide/batching-caching/withRequestCaching.ts

```

## Final Program

Assuming you've wired everything up correctly:

```ts filename="index.ts" file=<rootDir>/src/guide/batching-caching/final-program.ts

```

With this program, the `getTodos` operation retrieves the todos for each user. Then, the `Effect.forEach` function is used to notify the owner of each todo concurrently, without waiting for the notifications to complete.

The `repeat` function is applied to the entire chain of operations, and it ensures that the program repeats every 10 seconds using a fixed schedule. This means that the entire process, including fetching todos and sending notifications, will be executed repeatedly with a 10-second interval.

The program incorporates a caching mechanism, which prevents the same `GetUserById` operation from being executed more than once within a span of 1 minute (unless there are more than 65,000 users). This **default** caching behavior helps optimize the program's execution and reduces unnecessary requests to fetch user data.

Furthermore, the program is designed to send emails in batches, allowing for efficient processing and better utilization of resources.

## The Request Cache

There may be cases where you want to localize a cache (use a cache only for a part of your program)
or maybe you want a global cache with a different setup, or a mix of both.

To cover those scenarios you'd create a custom cache like the following:

```ts {13-17} filename="index.ts" file=<rootDir>/src/guide/batching-caching/final-program-with-cache.ts

```

Alternatively you can also directly construct a cache with `Request.makeCache({ capacity: 256, timeToLive: Duration.minutes(60) }){:ts}` and then use
`Effect.withRequestCache(program, myCache){:ts}` on a program to make sure the requests generated from that program uses
the custom cache (when enabled with `Effect.withRequestCaching("on"){:ts}`)

## How is this possible?

We recently introduced a new key primitive in the fiber that enables an execution to pause when it sees the program requires a request. In the process of pausing, the fiber will reify its stack into a continuation that can be externally performed.

```ts file=<rootDir>/src/guide/batching-caching/final-program-explained.ts

```

By using the functions provided by the `RequestBlock` module, you can combine requests from multiple blocked
effects. By using the function `Effect.blocked(requests, continuation){:ts}`, you can express an effect that is blocked
on `requests` that should continue with `continuation`.

## Using Cache Directly

There are many cases where you have functions `(key: Key) => Effect<R, E, A>{:ts}` that you would like to cache
and not necessarily every case is a good fit for the request model shown above. For example, non-batchable API
calls or intensive work.

Let's see how we would go about using cache:

```ts file=<rootDir>/src/guide/batching-caching/using-cache-directly.ts

```

<Warning>
  In order for the cache to correctly compare two `Key` values if you are not
  using primitives (e.g. string, boolean, number), you should use types that
  implement the [`Equal`](./trait/equal) interface.
</Warning>

There are many more methods available in the `Cache` module. As a next step, check out the reference docs!

## Reference Docs

The following are the reference docs for each of the mentioned modules:

`@effect/io`

- [Cache](https://effect-ts.github.io/io/modules/Cache.ts.html)
- [Effect](https://effect-ts.github.io/io/modules/Effect.ts.html)
- [Layer](https://effect-ts.github.io/io/modules/Layer.ts.html)
- [Request](https://effect-ts.github.io/io/modules/Request.ts.html)
- [RequestResolver](https://effect-ts.github.io/io/modules/RequestResolver.ts.html)
- [Schedule](https://effect-ts.github.io/io/modules/Schedule.ts.html)

`@effect/data`

- [Brand](https://effect-ts.github.io/data/modules/Brand.ts.html)
- [Data](https://effect-ts.github.io/data/modules/Data.ts.html)
- [Duration](https://effect-ts.github.io/data/modules/Duration.ts.html)
- [Equal](https://effect-ts.github.io/data/modules/Equal.ts.html)
- [Function](https://effect-ts.github.io/data/modules/Function.ts.html)
