---
title: Introduction to Effect AI
description: "Introduction to Effect's AI integrations, a set of packages for interacting with large language models"
sidebar:
  label: Introduction
  order: 0
---

import { Aside } from "@astrojs/starlight/components"

<Aside type="caution" title="Experimental Module">
  The Effect AI integration packages are currently in the experimental / alpha stage. We encourage your feedback to further improve their features.
</Aside>

Welcome to the documentation for Effect's AI integration packages ‚Äî a set of libraries designed to make working with large language models (LLMs) seamless, flexible, and provider-agnostic.

These packages enable you to write programs that describe *what* you want to do with an LLM ‚Äî generating completions, handling chat interactions, running function calls ‚Äî without having to commit to *how* or *where* those operations are executed. 

The core package, [`@effect/ai`](https://www.npmjs.com/package/@effect/ai), provides a high-level, unified interface for modeling LLM interactions, independent of any specific provider. Once you're ready to run your program, you can plug in the services your program requires from our LLM provider integration packages. 

This separation of concerns allows you to:
- Write clean, declarative business logic without worrying about provider-specific quirks
- Easily swap between or combine providers at runtime or during testing
- Take advantage of Effect‚Äôs features when building AI-driven workflows

Whether you're building an intelligent agent, an interactive chat app, or a system that leverages LLMs for background tasks, Effect's AI packages offer the flexibility and control you need!

Let‚Äôs dive in!

## Why Effect for AI?

Integrating LLMs isn‚Äôt just about sending API requests ‚Äî it‚Äôs handling streaming output, retries, rate limits, timeouts, and user-driven side effects, all while keeping your system stable and responsive. Effect provides simple, composable building blocks to model these workflows in a **safe**, **declarative**, and **composable** manner.

By using Effect for your LLM interactions you'll benefit from:

- üß© **Provider-Agnostic Architecture**  
  Write your business logic once, and defer choosing the underlying provider (OpenAI, Anthropic, local models, mocks, etc.) until runtime

- üß™ **Fully Testable**  
  Because LLM interactions are modeled via Effect services, you can mock, simulate, or snapshot responses just by providing an alternative implementation

- üßµ **Structured Concurrency**  
  Run concurrent LLM calls, cancel stale requests, stream partial results, or race multiple providers ‚Äî all safely managed by Effect‚Äôs structured concurrency model

- üîç **Observability**  
  Leverage Effect's built-in tracing, logging, and metrics to instrument your LLM interactions to gain deep insight into  performance bottlenecks or failures in production

...and much more!

## Core Concepts

Effect‚Äôs AI integrations are built around the idea of **provider-agnostic programming**. Instead of hardcoding calls to a specific LLM provider's API, you describe your interaction using the services provided by the base `@effect/ai` package.

These services expose capabilities such as:
- **Generating Text** ‚Äì single-shot text generation
- **Generating Embeddings** ‚Äì vector representations of text for search or retrieval
- **Tool Calling** ‚Äì structured outputs and tool usage 
- **Streaming** ‚Äì incremental output for memory efficiency and responsiveness 

Each of these services is defined as an *Effect service* ‚Äî meaning they can be injected, composed, and tested just like any other dependency in the Effect ecosystem.

This decoupling lets you write your AI code as a pure description of what you want to happen, and resolve *how* it happens later ‚Äî whether by wiring up OpenAI, Anthropic, a mock service for tests, or even your own custom LLM backend.

---

## Packages

Effect‚Äôs AI ecosystem is composed of several focused packages:

### `@effect/ai`

Defines the core abstractions for interacting with LLM provider services. This package defines the generic services and helper utilities needed to build AI-powered applications in a provider-agnostic way.

Use this package to:
- Define your application's interaction with an LLM
- Structure chat or completion flows using Effect
- Build type-safe, declarative AI logic

For detailed API documentation, see the [API Reference](https://effect-ts.github.io/effect/docs/ai/ai).

### `@effect/ai-openai`

Concrete implementations of services from `@effect/ai` backed by the [OpenAI API](https://platform.openai.com). 

Supported services include:
- `LanguageModel` (via OpenAI's [Chat Completions API](https://platform.openai.com/docs/api-reference/chat))
- `EmbeddingsModel` (via OpenAI's [Embeddings API](https://platform.openai.com/docs/api-reference/embeddings))

For detailed API documentation, see the [API Reference](https://effect-ts.github.io/effect/docs/ai/openai).

### `@effect/ai-anthropic`

Concrete implementations of services from `@effect/ai` backed by the [Anthropic API](https://docs.anthropic.com/en/api/getting-started).

Supported services include:
- `LanguageModel` (via Anthropic's [Messages API](https://docs.anthropic.com/en/api/messages))

For detailed API documentation, see the [API Reference](https://effect-ts.github.io/effect/docs/ai/anthropic).

### `@effect/ai-amazon-bedrock`

Concrete implementations of services from `@effect/ai` backed by [Amazon Bedrock](https://docs.aws.amazon.com/bedrock/latest/userguide/what-is-bedrock.html).

Supported services include:
- `LanguageModel` (via Amazon Bedrock's [Converse API](https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_Converse.html)

For detailed API documentation, see the [API Reference](https://effect-ts.github.io/effect/docs/ai/amazon-bedrock).

### `@effect/ai-google`

Concrete implementations of services from `@effect/ai` backed by [Google Generative AI](https://ai.google.dev/gemini-api/docs).

Supported services include:
- `LanguageModel` (via Google's [Gemini API](https://ai.google.dev/api)

For detailed API documentation, see the [API Reference](https://effect-ts.github.io/effect/docs/ai/google).
